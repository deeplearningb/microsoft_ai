{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data of dataset : tensor([[[-0.8335, -0.7993, -0.8335,  ..., -0.0629, -0.0458, -0.0458],\n",
      "         [-0.8335, -0.7993, -0.8164,  ..., -0.2513, -0.2342, -0.0972],\n",
      "         [-0.8335, -0.8164, -0.8335,  ..., -0.4054, -0.3883, -0.3198],\n",
      "         ...,\n",
      "         [-1.9809, -2.0152, -2.0152,  ..., -1.5357, -1.5528, -1.5357],\n",
      "         [-1.9467, -2.0152, -1.9980,  ..., -1.5185, -1.5185, -1.5357],\n",
      "         [-1.9980, -2.0152, -2.0323,  ..., -1.4672, -1.4843, -1.4843]],\n",
      "\n",
      "        [[ 0.0301,  0.0301,  0.0476,  ...,  1.1331,  1.1331,  1.0805],\n",
      "         [ 0.0301,  0.0476,  0.0826,  ...,  1.0455,  1.0280,  1.1331],\n",
      "         [ 0.0476,  0.0476,  0.0301,  ...,  0.9580,  0.9405,  1.0105],\n",
      "         ...,\n",
      "         [-1.2129, -1.2129, -1.2479,  ..., -0.4951, -0.5126, -0.5301],\n",
      "         [-1.2129, -1.2304, -1.2654,  ..., -0.4776, -0.4776, -0.4951],\n",
      "         [-1.2654, -1.2829, -1.3004,  ..., -0.4251, -0.4251, -0.4251]],\n",
      "\n",
      "        [[-1.7696, -1.8044, -1.7870,  ..., -1.7870, -1.7870, -1.7870],\n",
      "         [-1.7696, -1.7870, -1.7696,  ..., -1.7696, -1.8044, -1.7522],\n",
      "         [-1.7522, -1.7870, -1.8044,  ..., -1.7522, -1.8044, -1.8044],\n",
      "         ...,\n",
      "         [-1.8044, -1.7870, -1.8044,  ..., -1.7347, -1.7696, -1.7522],\n",
      "         [-1.7696, -1.7870, -1.7870,  ..., -1.8044, -1.8044, -1.7870],\n",
      "         [-1.7870, -1.7696, -1.8044,  ..., -1.8044, -1.8044, -1.7870]]]), 0\n",
      "Data of dataset : tensor([[[-1.2959, -1.4500, -1.4672,  ...,  1.3927,  1.3927,  1.3584],\n",
      "         [-1.3644, -1.4500, -1.6555,  ...,  1.3927,  1.3927,  1.3755],\n",
      "         [-1.4672, -1.6213, -1.6727,  ...,  1.3927,  1.3927,  1.3927],\n",
      "         ...,\n",
      "         [-0.0629, -0.0629,  0.0227,  ...,  0.5022,  0.2967,  0.3823],\n",
      "         [-0.0287, -0.0458,  0.0569,  ...,  0.4851,  0.3994,  0.5022],\n",
      "         [-0.0116,  0.0056,  0.0056,  ...,  0.5364,  0.4508,  0.5536]],\n",
      "\n",
      "        [[-0.6527, -0.7752, -0.7927,  ...,  1.8683,  1.8683,  1.8508],\n",
      "         [-0.7402, -0.7752, -0.9853,  ...,  1.8683,  1.8683,  1.8683],\n",
      "         [-0.8102, -0.9503, -1.0028,  ...,  1.8683,  1.8683,  1.8683],\n",
      "         ...,\n",
      "         [ 0.3277,  0.3978,  0.4853,  ...,  1.0805,  0.8704,  0.9580],\n",
      "         [ 0.3627,  0.4153,  0.5203,  ...,  1.0805,  0.9755,  1.0805],\n",
      "         [ 0.3803,  0.4503,  0.4678,  ...,  1.1506,  1.0455,  1.1331]],\n",
      "\n",
      "        [[-0.5670, -0.7064, -0.7238,  ...,  2.0823,  2.0823,  2.0474],\n",
      "         [-0.6367, -0.7064, -0.9156,  ...,  2.0823,  2.0823,  2.0823],\n",
      "         [-0.7413, -0.8807, -0.9156,  ...,  2.0823,  2.0823,  2.0823],\n",
      "         ...,\n",
      "         [ 0.4962,  0.5485,  0.6356,  ...,  1.2457,  1.0365,  1.1237],\n",
      "         [ 0.5311,  0.5659,  0.6705,  ...,  1.2457,  1.1237,  1.2282],\n",
      "         [ 0.5485,  0.6182,  0.6182,  ...,  1.2980,  1.2108,  1.2980]]]), 1\n",
      "Data of dataset : tensor([[[-0.5767, -0.6794, -0.6965,  ..., -0.4397, -0.3198, -0.2171],\n",
      "         [-0.6452, -0.7822, -0.7822,  ..., -0.3369, -0.4226, -0.3541],\n",
      "         [-0.7137, -0.9020, -0.9020,  ..., -0.3712, -0.5082, -0.4911],\n",
      "         ...,\n",
      "         [ 1.3584,  1.3927,  1.0502,  ...,  0.0398, -0.5253, -0.7993],\n",
      "         [ 1.4440,  1.3413,  0.7933,  ...,  0.0569, -0.4911, -0.9192],\n",
      "         [ 1.3413,  1.3927,  0.3309,  ..., -0.0801, -0.4568, -0.9534]],\n",
      "\n",
      "        [[-0.5301, -0.6001, -0.5826,  ...,  0.0126,  0.1001,  0.1702],\n",
      "         [-0.6001, -0.7227, -0.6702,  ...,  0.0651, -0.0574, -0.0049],\n",
      "         [-0.6702, -0.8102, -0.7927,  ...,  0.0126, -0.1625, -0.1800],\n",
      "         ...,\n",
      "         [ 1.6057,  1.7283,  1.4482,  ...,  0.6078, -0.0749, -0.4251],\n",
      "         [ 1.6933,  1.6933,  1.1856,  ...,  0.6254, -0.0224, -0.4951],\n",
      "         [ 1.6232,  1.7633,  0.7479,  ...,  0.5028,  0.0126, -0.5126]],\n",
      "\n",
      "        [[-1.1421, -1.1596, -1.0898,  ..., -0.8981, -0.9678, -0.9156],\n",
      "         [-1.1770, -1.2119, -1.1073,  ..., -0.8633, -1.0898, -1.0550],\n",
      "         [-1.1944, -1.2467, -1.1596,  ..., -0.9330, -1.1596, -1.1770],\n",
      "         ...,\n",
      "         [ 2.1171,  1.9254,  1.1237,  ..., -0.4101, -0.8981, -1.2119],\n",
      "         [ 2.1346,  1.8208,  0.8099,  ..., -0.3753, -0.8458, -1.2990],\n",
      "         [ 2.0125,  1.7685,  0.2348,  ..., -0.4973, -0.7761, -1.2816]]]), 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Debug. \\n    OpenCV(4.7.0) D:\\x07\\\\opencv-python\\\\opencv-python\\\\opencv\\\\modules\\\\imgproc\\\\src\\\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\\n    >>> !_src.empty() in function 이미지가 없으므로 imread()에서 읽은 이미지 확인, 경로 문제\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "class AlbumentationsDataset(Dataset):\n",
    "    def __init__(self, file_paths: list, labels, transform=None): \n",
    "        # transform default 값을 가지기 때문에 맨 끝에 정의해주지 않으면 에러가 나옴\n",
    "        # 여러 경로를 받기 때문에 리스트로 정의\n",
    "        self.file_paths = file_paths  \n",
    "        # self.file_lists = os.listdir(file_paths)\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels[index]\n",
    "        file_path = self.file_paths[index]\n",
    "\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # torchvision transform이 아닌 albumentation library 사용\n",
    "    albumentations_transform = A.Compose([ \n",
    "        A.Resize(256, 256),\n",
    "        A.RandomCrop(224, 224), # 이동하면서 random crop resize 내에서 이동해야 하므로 256 * 256보다는 작게 설정함\n",
    "        A.HorizontalFlip(), # 좌우 반전\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "    dataset = AlbumentationsDataset(\n",
    "        [\"./sample_data_01/train/dew/2208.jpg\", # -- ./ 현재 230619 폴더 내에서 있는 폴더 경로 확인, ../ 상위 폴더에서 들어갈 경로 \n",
    "         \"./sample_data_01/train/rain/1011.jpg\", # os 지정이 아닌 그냥 사진만 불러왔기 때문에 사진 경로까지 지정해줘야 하는 듯\n",
    "         \"./sample_data_01/train/frost/3600.jpg\"],\n",
    "         [0, 1, 2],\n",
    "        transform=albumentations_transform\n",
    "    )\n",
    "\n",
    "    for image, label in dataset:\n",
    "        print(f\"Data of dataset : {image}, {label}\")\n",
    "\n",
    "\n",
    "''' Debug. \n",
    "    OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
    "    >>> !_src.empty() in function 이미지가 없으므로 imread()에서 읽은 이미지 확인, 경로 문제'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
